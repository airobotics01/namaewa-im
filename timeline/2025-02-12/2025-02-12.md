## 📅 2025-02-12 - Daily Learning Log

### 💻 Example Code 

#### Agent code
[agent.py](./agent.py)

[agent.py running video](https://github.com/user-attachments/assets/55540455-8413-4386-a6a3-7863b16d0733)

---

1. LLM이 직접 Task를 선택하고, 적절한 Tool을 실행하도록 구현함.
LangGraph에서 사용했던 parse_task()가 필요 없어지고, LLM이 자연어로 요청을 해석해 Tool을 자동으로 선택함.

2. LLM이 모르면 검색하고, 문서를 읽어 요약하는 기능 추가
3. DuckDuckGoSearchRun()을 활용해 최신 정보 검색

* agent.invoke()의 반환값이 dict이므로 response["output"]을 사용해야한다.

### 📝 What I Learned Today

#### Agent Type
- 에이전트가 Tool을 호출하는 방식을 결정함
- LLM이 어떻게 Tool과 상호작용하며 추론 과정을 어떻게 수행할지를 결정함

**1. ZERO_SHOT_REACT_DESCRIPTION (기본형)**
Zero-Shot 기반의 ReAct(Reasoning + Acting) 방식으로, 가장 기본적인 "문제 해결 → 툴 사용" 패턴을 따른다.

**2. REACT_DOCSTORE (문서 검색 + ReAct)**
질문을 문서 검색(lookup) → 결과를 활용하여 답변하는 형식으로, 외부 문서를 참고해야하는 질의응답 시스템에 적합하다.

**3. SELF_ASK_WITH_SEARCH**
질문을 여러 개의 작은 질문으로 나눠서 검색하여 각각의 서브 질문에 대해 검색을 수행한 후 결론을 도출하기 때문에 복잡한 질문을 해결할 때 유용하다.

**4. CONVERSATIONAL_REACT_DESCRIPTION (대화형 ReAct)**
기존 대화 내역을 기억하면서 Tool을 활용하기 때문에 사용자의 이전 질문과 답변을 기억해야하는 경우에 적합하다.

**5. CHAT_ZERO_SHOT_REACT_DESCRIPTION (Chat 최적화)**
Zero-Shot ReAct 방식이지만 대화형 모델(ChatGPT 계열)에 최적화되어있어서 더 자연스러운 문장을 생성한다.

**6. STRUCTURED_CHAT_ZERO_SHOT_REACT_DESCRIPTION (구조화된 Tool 사용 가능)**
여러 개의 입력을 받는 Tool을 사용할 수 있도록 최적화되어있어서 멀티 input을 지원하는 API와 연동할 때 유용하다. 

**7. OPENAI_FUNCTIONS (OpenAI Functions 사용 최적화)**
OpenAI API 기반의 AI 에이전트 개발에 적합하다.

**8. OPENAI_MULTI_FUNCTIONS (여러 개의 OpenAI Function 지원)**
여러 개의 OpenAI Function을 동시에 실행할 수 있고, LLM이 필요에 따라 여러 기능을 한 번에 실행하도록 설계되어있다. 

### 🏆 Next Steps
기능에 따라 각각 다른 agent를 생성하여 상황에 맞게 실행 및 협력할 수 있도록 한다.
